base_path: /nfs/scratch2/shared_image_recog_ml
weights_path: ${base_path}/weights/dinov2


logging:
  project: cell-interactome
  entity: artificial-intelligence-research
  name: ${experiment_name}

seed: 0
TARGET_FILE_EXTENSION: ".pth"
search_suffix: "2D/**/*${TARGET_FILE_EXTENSION}"

# Environment Args
output_root: '../../'
pytorch_data_dir: '/pytorch-data'
submitting_to_aml: false


run_id: 0

# Dataset args
dataset: "" # use my own dataset

# Model Args
model_type: "ci_dinov2" # original: "vit"
activation_type: "token"

# Upsampling args
outlier_detection: True
upsampler_type: "jbu_stack"
downsampler_type: "attention"
max_pad: 20
max_zoom: 2
n_jitters: 5
random_projection: 30
crf_weight: 0.001
filter_ent_weight: 0.0
tv_weight: 0.0

implicit_sup_weight: 1.0

# Training args
batch_size: 6 # original: 4
epochs: 10
num_gpus: 1 # original: 1
num_workers: 24
lr: 1e-3

# No need to change
hydra:
  run:
    dir: "."
  output_subdir: ~

ckpt_file: ci_dinov2_jbu_stack__attention_crf_0.001_tv_0.0_ent_0.0_12000.ckpt
base_file_path: /nfs/scratch1/ajain/cell_interactome/src
featup_path: ${base_file_path}/third_party/
ckpt_path: ${featup_path}/checkpoints/checkpoints/jbu_${run_id}/${ckpt_file} 

model:
  train: 
    weights: ${weights_path}/pretrain_care_vits/ckpt_step_59999.pth # weights: ${weights_path}/pretrained/dinov2_vitg14_reg4_pretrain_ckpt.pth
    dino:
      freeze_head: false
    ibot:
      freeze_head: false
      separate_head: false
    student:
      freeze_backbone: true
      arch: vit_small
      patch_size: 14
      drop_path_rate: 0.4
      layerscale: 1.0e-05
      drop_path_uniform: true
      qkv_bias: true
      proj_bias: true
      ffn_bias: true
      ffn_layer: swiglufused
      num_register_tokens: 4
      block_chunks: 0
      interpolate_antialias: false
      interpolate_offset: 0.1
    crops:
      global_crops_scale:
        - 0.32
        - 1.0
      local_crops_number: 8
      local_crops_scale:
        - 0.05
        - 0.32
      global_crops_size: 224 # 518
      local_crops_size: 98
  featup:
    upsampler:
      type: jbu_stack
      use_norm: true
      weights: ""

train:
  resume: true
  dataset_path: ${base_path}/care_llsm_518
  path_to_txt: ${train.dataset_path}/train.txt
  output_dir: ${weights_path}/${logging.name}
  search_suffix: ${search_suffix}
  max_files: 1000000
  num_workers: 175 # reduced from 175
  log_interval: 10
  load_optim: true

